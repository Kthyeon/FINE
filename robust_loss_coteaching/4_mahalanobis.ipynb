{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn.covariance\n",
    "import scipy\n",
    "import pdb\n",
    "import numpy as np\n",
    "import random\n",
    "import statistics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import data_loader.data_loaders as module_data\n",
    "import loss as module_loss\n",
    "import model.metric as module_metric\n",
    "import model.model as module_arch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import model.model as module_arch\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import cluster\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from parse_config import ConfigParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path = './saved/mahalanobis/cifar10/resnet34/MultiStepLR/CCELoss/sym/0.8/'\n",
    "# cifar10_feature_4_0.npy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = './saved/models/cifar10/resnet34/MultiStepLR/CCELoss/sym/80/config_123.json'\n",
    "with open(config_file, 'r') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'cifar10_resnet34_multistep',\n",
       " 'n_gpu': 1,\n",
       " 'seed': 123,\n",
       " 'arch': {'type': 'resnet34', 'args': {'num_classes': 10}},\n",
       " 'num_classes': 10,\n",
       " 'data_loader': {'type': 'CIFAR10DataLoader',\n",
       "  'args': {'data_dir': './dir_to_data',\n",
       "   'batch_size': 128,\n",
       "   'shuffle': True,\n",
       "   'num_batches': 0,\n",
       "   'validation_split': 0,\n",
       "   'num_workers': 8,\n",
       "   'pin_memory': True}},\n",
       " 'optimizer': {'type': 'SGD',\n",
       "  'args': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.001}},\n",
       " 'train_loss': {'type': 'CCELoss'},\n",
       " 'val_loss': 'CrossEntropyLoss',\n",
       " 'metrics': ['my_metric', 'my_metric2'],\n",
       " 'lr_scheduler': {'type': 'MultiStepLR',\n",
       "  'args': {'milestones': [40, 80], 'gamma': 0.01}},\n",
       " 'trainer': {'epochs': 120,\n",
       "  'warmup': 0,\n",
       "  'save_dir': 'saved/',\n",
       "  'save_period': 1,\n",
       "  'verbosity': 2,\n",
       "  'label_dir': 'saved/',\n",
       "  'monitor': 'max test_my_metric',\n",
       "  'early_stop': 2000,\n",
       "  'tensorboard': False,\n",
       "  'mlflow': True,\n",
       "  '_percent': 'Percentage of noise',\n",
       "  'percent': 0.8,\n",
       "  '_begin': 'When to begin updating labels',\n",
       "  'begin': 0,\n",
       "  '_asym': 'symmetric noise if false',\n",
       "  'asym': False}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['trainer']['percent'] = 0.8\n",
    "config['trainer']['asym'] = False\n",
    "config['train_loss']['type'] = 'CCELoss'\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_path = './saved/models/cifar10/resnet34/MultiStepLR/GCELoss/sym/40/model_best123.pth'\n",
    "base_model = getattr(module_arch, config[\"arch\"]['type'])()\n",
    "checkpoint = torch.load(resume_path)\n",
    "state_dict = checkpoint['state_dict']\n",
    "base_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Train: 50000 Val: 0\n"
     ]
    }
   ],
   "source": [
    "# set seed\n",
    "random.seed(config['seed'])\n",
    "torch.manual_seed(config['seed'])\n",
    "torch.cuda.manual_seed_all(config['seed'])\n",
    "torch.backends.cudnn.deterministic = True\n",
    "np.random.seed(config['seed'])\n",
    "\n",
    "data_loader = getattr(module_data, config['data_loader']['type'])(\n",
    "    config['data_loader']['args']['data_dir'],\n",
    "    batch_size= 100,\n",
    "    shuffle=config['data_loader']['args']['shuffle'],\n",
    "    validation_split=0.0,\n",
    "    num_batches=config['data_loader']['args']['num_batches'],\n",
    "    training=True,\n",
    "    num_workers=config['data_loader']['args']['num_workers'],\n",
    "    pin_memory=config['data_loader']['args']['pin_memory'],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "if hasattr(data_loader.dataset, 'num_raw_example'):\n",
    "    num_examp = data_loader.dataset.num_raw_example\n",
    "else:\n",
    "    num_examp = len(data_loader.dataset)\n",
    "\n",
    "\n",
    "# criterion = getattr(module_loss, 'GCELoss')(q=config['train_loss']['args']['q'],\n",
    "#                                             k=config['train_loss']['args']['k'],\n",
    "#                                             trainset_size=num_examp,\n",
    "#                                             truncated=config['train_loss']['args']['truncated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Represent(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(Represent, self).__init__()\n",
    "        self.conv1 = base_model.conv1\n",
    "        self.bn1 = base_model.bn1\n",
    "        self.layer1 = base_model.layer1\n",
    "        self.layer2 = base_model.layer2\n",
    "        self.layer3 = base_model.layer3\n",
    "        self.layer4 = base_model.layer4\n",
    "        self.linear = base_model.linear\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        y = out.view(out.size(0), -1)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    #Feature Extractting\n",
    "    def feature_list(self, x):\n",
    "        output_list = []\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        for name, module in self.layer1._modules.items():\n",
    "            out = module(out)\n",
    "        for name, module in self.layer2._modules.items():\n",
    "            out = module(out)\n",
    "        for name, module in self.layer3._modules.items():\n",
    "            out = module(out)\n",
    "        for name, module in self.layer4._modules.items():\n",
    "            out = module(out)\n",
    "            output_list.append(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        y = self.linear(out)\n",
    "        return y, output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Represent(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:29<00:00, 16.83it/s]\n"
     ]
    }
   ],
   "source": [
    "isNoisy_list = np.empty((0,))\n",
    "isFalse_list = np.empty((0,))\n",
    "label_list = np.empty((0,))\n",
    "gt_list = np.empty((0,))\n",
    "conf_list = np.empty((0,))\n",
    "loss_list = np.empty((0,))\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "with tqdm(data_loader) as progress:\n",
    "    for batch_idx, (data, label, index, label_gt) in enumerate(progress):\n",
    "        data = data.to(device)\n",
    "        label, label_gt = label.long().to(device), label_gt.long().to(device)\n",
    "        output = model(data)\n",
    "        _,prediction = base_model(data)\n",
    "        loss = torch.nn.CrossEntropyLoss(reduction='none')(prediction, label)\n",
    "        confidence, _ = torch.max(torch.nn.functional.softmax(prediction, dim=1), dim=1)\n",
    "        isNoisy = label != label_gt\n",
    "        \n",
    "        gt_list = np.concatenate((gt_list, label_gt.cpu()))\n",
    "        label_list = np.concatenate((label_list, label.cpu()))\n",
    "        isNoisy_list = np.concatenate((isNoisy_list, isNoisy.cpu()))\n",
    "        conf_list = np.concatenate((conf_list, confidence.detach().cpu()))\n",
    "        loss_list = np.concatenate((loss_list, loss.detach().cpu()))\n",
    "        if batch_idx == 0:\n",
    "            out_list = output.detach().cpu()\n",
    "        else:\n",
    "            out_list = np.concatenate((out_list, output.detach().cpu()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labbb = torch.from_numpy(label_list).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 6, 1,  ..., 0, 1, 6])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 512)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_singular_value_vector(label_list, out_list):\n",
    "    \n",
    "    singular_dict = {}\n",
    "    v_ortho_dict = {}\n",
    "    \n",
    "    for index in np.unique(label_list):\n",
    "        u, s, v = np.linalg.svd(out_list[label_list==index])\n",
    "        singular_dict[index] = s[0] / s[1]\n",
    "        v_ortho_dict[index] = torch.from_numpy(v[:2])\n",
    "\n",
    "    return singular_dict, v_ortho_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singular_label(v_ortho_dict, model_represents, label):\n",
    "    \n",
    "    model_represents = torch.from_numpy(model_represents).to(device)\n",
    "    sing_lbl = torch.zeros(model_represents.shape[0]) \n",
    "    sin_score_lbl = torch.zeros(model_represents.shape[0])\n",
    "    \n",
    "    for i, data in enumerate(model_represents):\n",
    "        sin_score_lbl[i] = torch.dot(v_ortho_dict[label[i]][0], data).abs() - torch.dot(v_ortho_dict[label[i]][1], data).abs()\n",
    "        if torch.dot(v_ortho_dict[label[i]][0], data).abs() < torch.dot(v_ortho_dict[label[i]][1], data).abs():\n",
    "            sing_lbl[i] = 1\n",
    "        \n",
    "    return sing_lbl, sin_score_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "singular_dict, v_ortho_dict = get_singular_value_vector(label_list, out_list)\n",
    "\n",
    "for key in v_ortho_dict.keys():\n",
    "    v_ortho_dict[key] = v_ortho_dict[key].to(device)\n",
    "\n",
    "sing_lbl, sin_score_lbl = singular_label(v_ortho_dict, out_list, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sing_lbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23383, 512])\n"
     ]
    }
   ],
   "source": [
    "#Selected Output\n",
    "\n",
    "singular_output  = torch.from_numpy(out_list[sing_lbl==0])\n",
    "print(singular_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23383])\n"
     ]
    }
   ],
   "source": [
    "#Selected target correspoding to selected output\n",
    "sel_label = labbb[sing_lbl==0]\n",
    "print(sel_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute total mean and covariance for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_covariance(feature, total_label, num_classes):\n",
    "    group_lasso = sklearn.covariance.EmpiricalCovariance(assume_centered = False)   \n",
    "    new_feature, fraction_list = [], []\n",
    "    sample_mean_per_class = torch.Tensor(10, feature.size(1)).fill_(0).cuda()\n",
    "    total_label = total_label.cuda()\n",
    "\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        index_list = total_label.eq(i)\n",
    "        tmp_x = feature[index_list.nonzero(), :]\n",
    "        tmp_x = tmp_x.view(tmp_x.size(0), -1)\n",
    "        sample_mean_per_class[i].copy_(torch.mean(tmp_x, 0))\n",
    "\n",
    "        new_feature.append(tmp_x) \n",
    "        fraction_list.append(tmp_x.size(0))\n",
    "        \n",
    "    total_covariance = 0\n",
    "    for i in range(10):\n",
    "        flag = 0\n",
    "        X = 0\n",
    "        for j in range(fraction_list[i]):\n",
    "            tmp_feature = new_feature[i][j]\n",
    "            tmp_feature = tmp_feature - sample_mean_per_class[i]\n",
    "            tmp_feature = tmp_feature.view(-1,1)\n",
    "            if flag == 0:\n",
    "                X = tmp_feature.transpose(0,1)\n",
    "                flag = 1\n",
    "            else:\n",
    "                X = torch.cat((X, tmp_feature.transpose(0,1)),0)\n",
    "\n",
    "        group_lasso.fit(X.cpu().numpy())\n",
    "        inv_sample_conv = group_lasso.covariance_\n",
    "        inv_sample_conv = torch.from_numpy(inv_sample_conv).float().cuda()\n",
    "        if i == 0:\n",
    "            total_covariance = inv_sample_conv*fraction_list[i]\n",
    "        else:\n",
    "            total_covariance += inv_sample_conv*fraction_list[i]\n",
    "\n",
    "        total_covariance = total_covariance/sum(fraction_list)\n",
    "    new_precision = scipy.linalg.pinvh(total_covariance.cpu().numpy())\n",
    "    new_precision = torch.from_numpy(new_precision).float().cuda()\n",
    "    \n",
    "    return sample_mean_per_class, new_precision\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-6b5128979664>:10: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370172916/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  tmp_x = feature[index_list.nonzero(), :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1488, 0.4693, 0.0126,  ..., 0.0422, 0.2411, 0.0399],\n",
      "        [0.1410, 0.1092, 0.0486,  ..., 0.4310, 0.0667, 0.4055],\n",
      "        [0.1357, 0.1325, 0.0493,  ..., 0.0645, 0.1563, 0.0813],\n",
      "        ...,\n",
      "        [0.0124, 0.0815, 0.1552,  ..., 0.1266, 0.0193, 0.1286],\n",
      "        [0.4024, 0.2024, 0.0208,  ..., 0.1251, 0.2460, 0.1069],\n",
      "        [0.1155, 0.3591, 0.0196,  ..., 0.1225, 0.1191, 0.1172]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 4.6212e+02,  1.1194e+02,  5.6258e+01,  ..., -5.0781e+01,\n",
      "          2.8196e+01, -4.1597e+01],\n",
      "        [ 1.1194e+02,  5.6627e+02, -5.8346e+01,  ..., -5.5217e-01,\n",
      "          5.9187e+01, -3.4841e+00],\n",
      "        [ 5.6258e+01, -5.8346e+01,  3.3814e+02,  ...,  3.3974e+01,\n",
      "          6.6227e+01, -4.5310e+01],\n",
      "        ...,\n",
      "        [-5.0781e+01, -5.5217e-01,  3.3974e+01,  ...,  4.3561e+02,\n",
      "         -2.8437e+01, -1.4687e+01],\n",
      "        [ 2.8196e+01,  5.9187e+01,  6.6227e+01,  ..., -2.8437e+01,\n",
      "          6.0587e+02, -1.3664e+02],\n",
      "        [-4.1597e+01, -3.4841e+00, -4.5310e+01,  ..., -1.4687e+01,\n",
      "         -1.3664e+02,  4.9091e+02]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sample_mean, sample_precision = get_mean_covariance(singular_output.cuda(), sel_label, 10)\n",
    "print(sample_mean)\n",
    "print(sample_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 512])\n",
      "tensor([[ 4.6212e+02,  1.1194e+02,  5.6258e+01,  ..., -5.0781e+01,\n",
      "          2.8196e+01, -4.1597e+01],\n",
      "        [ 1.1194e+02,  5.6627e+02, -5.8346e+01,  ..., -5.5217e-01,\n",
      "          5.9187e+01, -3.4841e+00],\n",
      "        [ 5.6258e+01, -5.8346e+01,  3.3814e+02,  ...,  3.3974e+01,\n",
      "          6.6227e+01, -4.5310e+01],\n",
      "        ...,\n",
      "        [-5.0781e+01, -5.5217e-01,  3.3974e+01,  ...,  4.3561e+02,\n",
      "         -2.8437e+01, -1.4687e+01],\n",
      "        [ 2.8196e+01,  5.9187e+01,  6.6227e+01,  ..., -2.8437e+01,\n",
      "          6.0587e+02, -1.3664e+02],\n",
      "        [-4.1597e+01, -3.4841e+00, -4.5310e+01,  ..., -1.4687e+01,\n",
      "         -1.3664e+02,  4.9091e+02]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(sample_precision.shape)\n",
    "print(sample_precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahalanobis_distance(feature, sample_mean, inverse_covariance):\n",
    "    group_lasso = sklearn.covariance.EmpiricalCovariance(assume_centered=False)\n",
    "    temp_batch = 100\n",
    "    total, mahalanobis_score = 0, 0\n",
    "    \n",
    "    for data_index in range(int(np.ceil(feature.size(0)/temp_batch))):\n",
    "        temp_feature = feature[total : total + temp_batch].cuda()        \n",
    "        gaussian_score = 0\n",
    "        batch_sample_mean = sample_mean\n",
    "        zero_f = temp_feature - batch_sample_mean\n",
    "        term_gau = 0.5*torch.mm(torch.mm(zero_f, inverse_covariance), zero_f.t()).diag()\n",
    "        # concat data\n",
    "        if total == 0:\n",
    "            mahalanobis_score = term_gau.view(-1,1)\n",
    "        else:\n",
    "            mahalanobis_score = torch.cat((mahalanobis_score, term_gau.view(-1,1)), 0)\n",
    "        total += temp_batch\n",
    "    \n",
    "    mahalanobis_score = mahalanobis_score.view(-1)\n",
    "        \n",
    "    return mahalanobis_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mal_list(feature, total_target, sam_mean, sam_precision, num_classes):\n",
    "    mahal_list = []\n",
    "    for i in range(10):\n",
    "        index_list = total_target.eq(i)\n",
    "        tmp_x = feature[index_list.nonzero(), :]\n",
    "        tmp_x = tmp_x.view(tmp_x.size(0), -1)\n",
    "        mahal_list.append(mahalanobis_distance(tmp_x.cuda(), sam_mean[i], sam_precision))\n",
    "        \n",
    "    return mahal_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = mal_list(singular_output.cuda(), sel_label, sample_mean, sample_precision, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2730])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aa list containing mahalanobis distance across class\n",
    "aa[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 max: tensor(11734.8428, device='cuda:0')\n",
      "class 0 min: tensor(106.4293, device='cuda:0')\n",
      "class 0 median: tensor(317.9929, device='cuda:0')\n",
      "class 1 max: tensor(18957.8809, device='cuda:0')\n",
      "class 1 min: tensor(26.8511, device='cuda:0')\n",
      "class 1 median: tensor(134.4972, device='cuda:0')\n",
      "class 2 max: tensor(18829.3984, device='cuda:0')\n",
      "class 2 min: tensor(488.5957, device='cuda:0')\n",
      "class 2 median: tensor(2377.7825, device='cuda:0')\n",
      "class 3 max: tensor(24590.2773, device='cuda:0')\n",
      "class 3 min: tensor(647.1175, device='cuda:0')\n",
      "class 3 median: tensor(2177.1340, device='cuda:0')\n",
      "class 4 max: tensor(18941.7949, device='cuda:0')\n",
      "class 4 min: tensor(535.7272, device='cuda:0')\n",
      "class 4 median: tensor(2916.7783, device='cuda:0')\n",
      "class 5 max: tensor(15086.3076, device='cuda:0')\n",
      "class 5 min: tensor(378.2017, device='cuda:0')\n",
      "class 5 median: tensor(3880.2053, device='cuda:0')\n",
      "class 6 max: tensor(15015.7568, device='cuda:0')\n",
      "class 6 min: tensor(130.9791, device='cuda:0')\n",
      "class 6 median: tensor(760.9814, device='cuda:0')\n",
      "class 7 max: tensor(25511.8516, device='cuda:0')\n",
      "class 7 min: tensor(276.2981, device='cuda:0')\n",
      "class 7 median: tensor(575.2277, device='cuda:0')\n",
      "class 8 max: tensor(6957.2090, device='cuda:0')\n",
      "class 8 min: tensor(31.0281, device='cuda:0')\n",
      "class 8 median: tensor(151.3114, device='cuda:0')\n",
      "class 9 max: tensor(4134.6094, device='cuda:0')\n",
      "class 9 min: tensor(22.2738, device='cuda:0')\n",
      "class 9 median: tensor(143.3722, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('class',i,'max:', max(aa[i]))\n",
    "    print('class',i,'min:', min(aa[i]))\n",
    "    print('class',i,'median:', statistics.median(aa[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = aa[0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 12.,  77., 175., 202., 198., 222., 181., 146., 139., 125.,  94.,\n",
       "         81.,  67.,  60.,  57.,  62.,  37.,  31.,  34.,  27.,  32.,  12.,\n",
       "         25.,  20.,  20.,  14.,  21.,  12.,  17.,   8.,  11.,   9.,  13.,\n",
       "          5.,   6.,   3.,   7.,   5.,   7.,   2.,   6.,   6.,   7.,  10.,\n",
       "          5.,   6.,   5.,   3.,   3.,   4.,   3.,   4.,   0.,   4.,   1.,\n",
       "          1.,   3.,   2.,   1.,   2.,   2.,   6.,   0.,   1.,   2.,   1.,\n",
       "          1.,   1.,   0.,   1.,   0.,   2.,   2.,   2.,   0.,   1.,   1.,\n",
       "          0.,   0.,   2.,   2.,   2.,   1.,   2.,   2.,   1.,   1.,   0.,\n",
       "          2.,   1.,   3.,   3.,   3.,   1.,   2.,   1.,   2.,   2.,   0.,\n",
       "          0.,   2.,   2.,   0.,   2.,   1.,   2.,   1.,   2.,   1.,   1.,\n",
       "          1.,   0.,   0.,   4.,   1.,   1.,   0.,   1.,   3.,   2.,   1.,\n",
       "          0.,   1.,   3.,   1.,   2.,   2.,   0.,   2.,   1.,   1.,   0.,\n",
       "          0.,   2.,   2.,   2.,   1.,   0.,   2.,   4.,   0.,   0.,   0.,\n",
       "          0.,   2.,   0.,   1.,   0.,   2.,   2.,   1.,   0.,   0.,   0.,\n",
       "          0.,   2.,   2.,   1.,   0.,   1.,   2.,   2.,   0.,   2.,   0.,\n",
       "          4.,   0.,   4.,   3.,   2.,   0.,   4.,   0.,   1.,   4.,   1.,\n",
       "          0.,   1.,   4.,   0.,   0.,   1.,   0.,   2.,   0.,   2.,   0.,\n",
       "          3.,   1.,   0.,   0.,   1.,   0.,   1.,   0.,   0.,   0.,   3.,\n",
       "          1.,   3.,   4.,   3.,   2.,   1.,   2.,   1.,   3.,   1.,   2.,\n",
       "          0.,   2.,   1.,   1.,   1.,   1.,   1.,   1.,   2.,   2.,   2.,\n",
       "          0.,   1.,   1.,   2.,   6.,   1.,   1.,   2.,   1.,   0.,   3.,\n",
       "          3.,   1.,   3.,   2.,   3.,   1.,   2.,   1.,   4.,   1.,   1.,\n",
       "          3.,   2.,   2.,   1.,   3.,   3.,   1.,   0.,   1.,   0.,   1.,\n",
       "          2.,   0.,   1.,   3.,   1.,   1.,   1.,   1.,   4.,   2.,   0.,\n",
       "          3.,   3.,   2.,   2.,   0.,   1.,   0.,   1.,   0.,   1.,   0.,\n",
       "          1.,   0.,   1.,   1.,   2.,   3.,   2.,   1.,   0.,   1.,   0.,\n",
       "          2.,   1.,   0.,   0.,   0.,   3.,   0.,   2.,   0.,   0.,   1.,\n",
       "          0.,   2.,   1.,   1.,   0.,   1.,   2.,   1.,   0.,   1.,   0.,\n",
       "          1.,   2.,   1.,   0.,   0.,   1.,   1.,   0.,   0.,   0.,   0.,\n",
       "          2.,   1.,   0.,   3.,   0.,   0.,   1.,   2.,   0.,   0.,   1.,\n",
       "          1.,   0.,   0.,   2.,   1.,   0.,   1.,   1.,   1.,   0.,   0.,\n",
       "          0.,   0.,   1.,   0.,   1.,   0.,   2.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,\n",
       "          0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   2.,   0.,   0.,   1.,\n",
       "          0.,   1.,   0.,   1.,   0.,   0.,   0.,   1.,   0.,   0.,   1.,\n",
       "          0.,   1.,   0.,   1.,   1.,   0.,   0.,   0.,   1.,   1.,   0.,\n",
       "          1.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   1.,   1.,   0.,\n",
       "          0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   1.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   1.]),\n",
       " array([  106.42929,   129.68611,   152.94295,   176.19977,   199.4566 ,\n",
       "          222.71342,   245.97025,   269.22708,   292.48392,   315.74072,\n",
       "          338.99756,   362.2544 ,   385.5112 ,   408.76804,   432.02487,\n",
       "          455.2817 ,   478.5385 ,   501.79535,   525.0522 ,   548.309  ,\n",
       "          571.56586,   594.82263,   618.07947,   641.3363 ,   664.59314,\n",
       "          687.85   ,   711.1068 ,   734.36365,   757.6204 ,   780.87726,\n",
       "          804.1341 ,   827.3909 ,   850.64777,   873.9046 ,   897.16144,\n",
       "          920.4182 ,   943.67505,   966.9319 ,   990.1887 ,  1013.44556,\n",
       "         1036.7024 ,  1059.9592 ,  1083.2161 ,  1106.4729 ,  1129.7297 ,\n",
       "         1152.9865 ,  1176.2433 ,  1199.5001 ,  1222.757  ,  1246.0138 ,\n",
       "         1269.2706 ,  1292.5275 ,  1315.7843 ,  1339.0411 ,  1362.298  ,\n",
       "         1385.5548 ,  1408.8116 ,  1432.0685 ,  1455.3252 ,  1478.582  ,\n",
       "         1501.8389 ,  1525.0957 ,  1548.3525 ,  1571.6094 ,  1594.8662 ,\n",
       "         1618.123  ,  1641.3799 ,  1664.6367 ,  1687.8936 ,  1711.1504 ,\n",
       "         1734.4072 ,  1757.6641 ,  1780.9208 ,  1804.1776 ,  1827.4344 ,\n",
       "         1850.6913 ,  1873.9481 ,  1897.205  ,  1920.4618 ,  1943.7186 ,\n",
       "         1966.9755 ,  1990.2323 ,  2013.4891 ,  2036.746  ,  2060.0027 ,\n",
       "         2083.2595 ,  2106.5164 ,  2129.7732 ,  2153.03   ,  2176.2869 ,\n",
       "         2199.5437 ,  2222.8005 ,  2246.0574 ,  2269.3142 ,  2292.571  ,\n",
       "         2315.828  ,  2339.0847 ,  2362.3416 ,  2385.5984 ,  2408.8552 ,\n",
       "         2432.112  ,  2455.369  ,  2478.6257 ,  2501.8826 ,  2525.1394 ,\n",
       "         2548.3962 ,  2571.6528 ,  2594.9097 ,  2618.1665 ,  2641.4233 ,\n",
       "         2664.6802 ,  2687.937  ,  2711.1938 ,  2734.4507 ,  2757.7075 ,\n",
       "         2780.9644 ,  2804.2212 ,  2827.478  ,  2850.7349 ,  2873.9917 ,\n",
       "         2897.2485 ,  2920.5054 ,  2943.7622 ,  2967.019  ,  2990.276  ,\n",
       "         3013.5327 ,  3036.7896 ,  3060.0464 ,  3083.3032 ,  3106.56   ,\n",
       "         3129.817  ,  3153.0737 ,  3176.3306 ,  3199.5872 ,  3222.844  ,\n",
       "         3246.1008 ,  3269.3577 ,  3292.6145 ,  3315.8713 ,  3339.1282 ,\n",
       "         3362.385  ,  3385.6418 ,  3408.8987 ,  3432.1555 ,  3455.4124 ,\n",
       "         3478.6692 ,  3501.926  ,  3525.1829 ,  3548.4397 ,  3571.6965 ,\n",
       "         3594.9534 ,  3618.2102 ,  3641.467  ,  3664.7239 ,  3687.9807 ,\n",
       "         3711.2375 ,  3734.4944 ,  3757.7512 ,  3781.008  ,  3804.265  ,\n",
       "         3827.5215 ,  3850.7783 ,  3874.0352 ,  3897.292  ,  3920.5488 ,\n",
       "         3943.8057 ,  3967.0625 ,  3990.3193 ,  4013.5762 ,  4036.833  ,\n",
       "         4060.0898 ,  4083.3467 ,  4106.6035 ,  4129.8604 ,  4153.117  ,\n",
       "         4176.374  ,  4199.631  ,  4222.8877 ,  4246.1445 ,  4269.4014 ,\n",
       "         4292.658  ,  4315.915  ,  4339.172  ,  4362.4287 ,  4385.6855 ,\n",
       "         4408.9424 ,  4432.199  ,  4455.456  ,  4478.713  ,  4501.9697 ,\n",
       "         4525.2266 ,  4548.4834 ,  4571.74   ,  4594.997  ,  4618.254  ,\n",
       "         4641.5107 ,  4664.7676 ,  4688.0244 ,  4711.2812 ,  4734.538  ,\n",
       "         4757.795  ,  4781.0513 ,  4804.308  ,  4827.565  ,  4850.822  ,\n",
       "         4874.0786 ,  4897.3354 ,  4920.5923 ,  4943.849  ,  4967.106  ,\n",
       "         4990.363  ,  5013.6196 ,  5036.8765 ,  5060.1333 ,  5083.39   ,\n",
       "         5106.647  ,  5129.904  ,  5153.1606 ,  5176.4175 ,  5199.6743 ,\n",
       "         5222.931  ,  5246.188  ,  5269.445  ,  5292.7017 ,  5315.9585 ,\n",
       "         5339.2153 ,  5362.472  ,  5385.729  ,  5408.986  ,  5432.2427 ,\n",
       "         5455.4995 ,  5478.7563 ,  5502.013  ,  5525.27   ,  5548.527  ,\n",
       "         5571.7837 ,  5595.0405 ,  5618.2974 ,  5641.554  ,  5664.811  ,\n",
       "         5688.068  ,  5711.3247 ,  5734.5815 ,  5757.8384 ,  5781.095  ,\n",
       "         5804.352  ,  5827.609  ,  5850.8657 ,  5874.1226 ,  5897.3794 ,\n",
       "         5920.636  ,  5943.893  ,  5967.15   ,  5990.4067 ,  6013.6636 ,\n",
       "         6036.9204 ,  6060.177  ,  6083.4336 ,  6106.6904 ,  6129.9473 ,\n",
       "         6153.204  ,  6176.461  ,  6199.718  ,  6222.9746 ,  6246.2314 ,\n",
       "         6269.4883 ,  6292.745  ,  6316.002  ,  6339.259  ,  6362.5156 ,\n",
       "         6385.7725 ,  6409.0293 ,  6432.286  ,  6455.543  ,  6478.8    ,\n",
       "         6502.0566 ,  6525.3135 ,  6548.5703 ,  6571.827  ,  6595.084  ,\n",
       "         6618.341  ,  6641.5977 ,  6664.8545 ,  6688.1113 ,  6711.368  ,\n",
       "         6734.625  ,  6757.882  ,  6781.1387 ,  6804.3955 ,  6827.6523 ,\n",
       "         6850.909  ,  6874.166  ,  6897.423  ,  6920.6797 ,  6943.9365 ,\n",
       "         6967.1934 ,  6990.45   ,  7013.707  ,  7036.964  ,  7060.2207 ,\n",
       "         7083.4775 ,  7106.7344 ,  7129.991  ,  7153.248  ,  7176.505  ,\n",
       "         7199.7617 ,  7223.0186 ,  7246.2754 ,  7269.532  ,  7292.789  ,\n",
       "         7316.0454 ,  7339.3022 ,  7362.559  ,  7385.816  ,  7409.0728 ,\n",
       "         7432.3296 ,  7455.5864 ,  7478.8433 ,  7502.1    ,  7525.357  ,\n",
       "         7548.614  ,  7571.8706 ,  7595.1274 ,  7618.3843 ,  7641.641  ,\n",
       "         7664.898  ,  7688.155  ,  7711.4116 ,  7734.6685 ,  7757.9253 ,\n",
       "         7781.182  ,  7804.439  ,  7827.696  ,  7850.9526 ,  7874.2095 ,\n",
       "         7897.4663 ,  7920.723  ,  7943.98   ,  7967.237  ,  7990.4937 ,\n",
       "         8013.7505 ,  8037.0073 ,  8060.264  ,  8083.521  ,  8106.778  ,\n",
       "         8130.0347 ,  8153.2915 ,  8176.5483 ,  8199.805  ,  8223.062  ,\n",
       "         8246.318  ,  8269.575  ,  8292.832  ,  8316.089  ,  8339.346  ,\n",
       "         8362.603  ,  8385.859  ,  8409.116  ,  8432.373  ,  8455.63   ,\n",
       "         8478.887  ,  8502.144  ,  8525.4    ,  8548.657  ,  8571.914  ,\n",
       "         8595.171  ,  8618.428  ,  8641.685  ,  8664.941  ,  8688.198  ,\n",
       "         8711.455  ,  8734.712  ,  8757.969  ,  8781.226  ,  8804.482  ,\n",
       "         8827.739  ,  8850.996  ,  8874.253  ,  8897.51   ,  8920.767  ,\n",
       "         8944.023  ,  8967.28   ,  8990.537  ,  9013.794  ,  9037.051  ,\n",
       "         9060.308  ,  9083.564  ,  9106.821  ,  9130.078  ,  9153.335  ,\n",
       "         9176.592  ,  9199.849  ,  9223.105  ,  9246.362  ,  9269.619  ,\n",
       "         9292.876  ,  9316.133  ,  9339.39   ,  9362.646  ,  9385.903  ,\n",
       "         9409.16   ,  9432.417  ,  9455.674  ,  9478.931  ,  9502.1875 ,\n",
       "         9525.444  ,  9548.701  ,  9571.958  ,  9595.215  ,  9618.472  ,\n",
       "         9641.729  ,  9664.985  ,  9688.242  ,  9711.499  ,  9734.756  ,\n",
       "         9758.013  ,  9781.27   ,  9804.526  ,  9827.783  ,  9851.04   ,\n",
       "         9874.297  ,  9897.554  ,  9920.811  ,  9944.067  ,  9967.324  ,\n",
       "         9990.581  , 10013.838  , 10037.095  , 10060.352  , 10083.608  ,\n",
       "        10106.865  , 10130.122  , 10153.379  , 10176.636  , 10199.893  ,\n",
       "        10223.149  , 10246.406  , 10269.663  , 10292.92   , 10316.177  ,\n",
       "        10339.434  , 10362.69   , 10385.947  , 10409.204  , 10432.461  ,\n",
       "        10455.718  , 10478.974  , 10502.23   , 10525.487  , 10548.744  ,\n",
       "        10572.001  , 10595.258  , 10618.515  , 10641.771  , 10665.028  ,\n",
       "        10688.285  , 10711.542  , 10734.799  , 10758.056  , 10781.3125 ,\n",
       "        10804.569  , 10827.826  , 10851.083  , 10874.34   , 10897.597  ,\n",
       "        10920.854  , 10944.11   , 10967.367  , 10990.624  , 11013.881  ,\n",
       "        11037.138  , 11060.395  , 11083.651  , 11106.908  , 11130.165  ,\n",
       "        11153.422  , 11176.679  , 11199.936  , 11223.192  , 11246.449  ,\n",
       "        11269.706  , 11292.963  , 11316.22   , 11339.477  , 11362.733  ,\n",
       "        11385.99   , 11409.247  , 11432.504  , 11455.761  , 11479.018  ,\n",
       "        11502.274  , 11525.531  , 11548.788  , 11572.045  , 11595.302  ,\n",
       "        11618.559  , 11641.815  , 11665.072  , 11688.329  , 11711.586  ,\n",
       "        11734.843  ], dtype=float32),\n",
       " [<matplotlib.patches.Polygon at 0x7f093e5bd370>])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(aaa, histtype='stepfilled', alpha=0.3, bins=500, density=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for computing MCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (data, target, index, label_gt) in enumerate(data_loader):\n",
    "    data, target, label_gt = data.cuda(), target.cuda(), label_gt.cuda()\n",
    "    if batch_idx == 0:\n",
    "        total_data = data\n",
    "        total_target = target\n",
    "        total_label_gt = label_gt\n",
    "    else:\n",
    "        total_data = torch.cat((total_data, data), 0)\n",
    "        total_target = torch.cat((total_target, target), 0)\n",
    "        total_label_gt = torch.cat((total_label_gt, label_gt), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise rate:  0.72072\n"
     ]
    }
   ],
   "source": [
    "#Noise rate check\n",
    "tmp = 0\n",
    "for i in range(len(total_label_gt)):\n",
    "    if total_target[i] != total_label_gt[i]:\n",
    "        tmp += 1\n",
    "print('Noise rate: ', tmp/len(total_label_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-6d51e0369ed1>:5: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  temp_x = Variable(temp_x, volatile=True)\n",
      "<ipython-input-41-6d51e0369ed1>:14: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data = Variable(data, volatile=True)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "temp_x = torch.rand(2,3,32,32).cuda()\n",
    "temp_x = Variable(temp_x, volatile=True)\n",
    "temp_list = model.feature_list(temp_x)[1]\n",
    "num_output = len(temp_list) # Number of layers that extracts feature\n",
    "total_final_feature = [0]*num_output #Extracted Features\n",
    "total = 0\n",
    "batch_size = 100\n",
    "\n",
    "for data_index in range(int(np.floor(total_data.size(0)/batch_size))):\n",
    "    data = total_data[total : total + batch_size]\n",
    "    data = Variable(data, volatile=True)\n",
    "\n",
    "    _, out_features = model.feature_list(data)\n",
    "    for i in range(num_output):\n",
    "        out_features[i] = out_features[i].view(out_features[i].size(0), out_features[i].size(1), -1)\n",
    "        out_features[i] = torch.mean(out_features[i].data, 2)\n",
    "        if total == 0:\n",
    "            total_final_feature[i] = out_features[i].cpu().clone()\n",
    "        else:\n",
    "            total_final_feature[i] = torch.cat((total_final_feature[i], out_features[i].cpu().clone()), 0)\n",
    "    total += batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only for using saved feature .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_feature_list = []\n",
    "for i in range(3):\n",
    "    tmp_feature = torch.from_numpy(np.load(read_path+'cifar10_feature_4_'+str(i)+'.npy')).cpu()\n",
    "    total_feature_list.append(tmp_feature)\n",
    "    print(type(tmp_feature))\n",
    "\n",
    "total_target = torch.from_numpy(np.load('./saved/mahalanobis/cifar10/resnet34/MultiStepLR/GCELoss/sym/0.4/cifar10_target_noise.npy')).long()\n",
    "total_label_gt = torch.from_numpy(np.load('./saved/mahalanobis/cifar10/resnet34/MultiStepLR/GCELoss/sym/0.4/cifar10_label_gt.npy')).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobis for MCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features of 3 layers [50000, 512]\n",
    "total_final_feature\n",
    "\n",
    "# target including noisy labels\n",
    "total_target\n",
    "\n",
    "# ground truth label\n",
    "total_label_gt\n",
    "\n",
    "#\n",
    "num_output = len(total_final_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Sample Mean\n",
    "def random_sample_mean(feature, total_label, num_classes):\n",
    "    \n",
    "    group_lasso = sklearn.covariance.EmpiricalCovariance(assume_centered = False)    \n",
    "    new_feature, fraction_list = [], []\n",
    "    frac = 0.7\n",
    "    sample_mean_per_class = torch.Tensor(num_classes, feature.size(1)).fill_(0).cuda()\n",
    "    total_label = total_label.cuda()\n",
    "\n",
    "    \n",
    "    total_selected_list = []\n",
    "    for i in range(num_classes):\n",
    "        index_list = total_label.eq(i)\n",
    "        temp_feature = feature[index_list.nonzero(), :]\n",
    "        temp_feature = temp_feature.view(temp_feature.size(0), -1)\n",
    "\n",
    "        shuffler_idx = torch.randperm(temp_feature.size(0))\n",
    "        index = shuffler_idx[:int(temp_feature.size(0)*frac)]\n",
    "        fraction_list.append(int(temp_feature.size(0)*frac))\n",
    "        total_selected_list.append(index_list.nonzero()[index.cuda()])\n",
    "\n",
    "\n",
    "        selected_feature = torch.index_select(temp_feature, 0, index.cuda())\n",
    "        new_feature.append(selected_feature)\n",
    "        sample_mean_per_class[i].copy_(torch.mean(selected_feature, 0))\n",
    "\n",
    "    total_covariance = 0\n",
    "    for i in range(num_classes):\n",
    "        flag = 0\n",
    "        X = 0\n",
    "        for j in range(fraction_list[i]):\n",
    "            temp_feature = new_feature[i][j]\n",
    "\n",
    "            temp_feature = temp_feature - sample_mean_per_class[i]\n",
    "            temp_feature = temp_feature.view(-1,1)\n",
    "            if flag  == 0:\n",
    "                X = temp_feature.transpose(0,1)\n",
    "                flag = 1\n",
    "            else:\n",
    "                X = torch.cat((X,temp_feature.transpose(0,1)),0)\n",
    "            # find inverse            \n",
    "        group_lasso.fit(X.cpu().numpy())\n",
    "        inv_sample_conv = group_lasso.covariance_\n",
    "        inv_sample_conv = torch.from_numpy(inv_sample_conv).float().cuda()\n",
    "        if i == 0:\n",
    "            total_covariance = inv_sample_conv*fraction_list[i]\n",
    "        else:\n",
    "            total_covariance += inv_sample_conv*fraction_list[i]\n",
    "        total_covariance = total_covariance/sum(fraction_list)\n",
    "    new_precision = scipy.linalg.pinvh(total_covariance.cpu().numpy())\n",
    "    new_precision = torch.from_numpy(new_precision).float().cuda()\n",
    "\n",
    "    \n",
    "    return sample_mean_per_class, new_precision, total_selected_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Sample Mean\n"
     ]
    }
   ],
   "source": [
    "print('Random Sample Mean')\n",
    "sample_mean_list, sample_precision_list = [], []\n",
    "total_label_list = [total_target for i in range(3)]\n",
    "\n",
    "for index in range(3):\n",
    "    sample_mean, sample_precision, _ = random_sample_mean(total_final_feature[index].cuda(), total_label_list[index].cuda(), config['num_classes'])\n",
    "    sample_mean_list.append(sample_mean)\n",
    "    sample_precision_list.append(sample_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_mean_list)\n",
    "len(sample_precision_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 920.1540,  -43.0862,   97.5807,  ..., -179.5037,  -16.3750,\n",
       "           21.4863],\n",
       "        [ -43.0862, 1197.1914,  -26.9887,  ...,  114.3012,   12.1584,\n",
       "          -52.1778],\n",
       "        [  97.5807,  -26.9887,  506.6533,  ..., -175.3536,   47.5371,\n",
       "           99.1817],\n",
       "        ...,\n",
       "        [-179.5037,  114.3013, -175.3537,  ..., 1130.5620,   23.0996,\n",
       "         -278.0416],\n",
       "        [ -16.3750,   12.1584,   47.5370,  ...,   23.0996,  771.8832,\n",
       "         -190.1959],\n",
       "        [  21.4863,  -52.1778,   99.1817,  ..., -278.0416, -190.1959,\n",
       "          927.7223]], device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_precision_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "#MCD single\n",
    "def MCD_single(feature, sample_mean, inverse_covariance):\n",
    "    group_lasso = sklearn.covariance.EmpiricalCovariance(assume_centered=False)\n",
    "    temp_batch = 100\n",
    "    total, mahalanobis_score = 0, 0\n",
    "    frac = 0.7 #fraction N_c+d+1 / 2\n",
    "    for data_index in range(int(np.ceil(feature.size(0)/temp_batch))):\n",
    "        temp_feature = feature[total : total + temp_batch].cuda()        \n",
    "        gaussian_score = 0\n",
    "        batch_sample_mean = sample_mean\n",
    "        zero_f = temp_feature - batch_sample_mean\n",
    "        term_gau = -0.5*torch.mm(torch.mm(zero_f, inverse_covariance), zero_f.t()).diag()\n",
    "        # concat data\n",
    "        if total == 0:\n",
    "            mahalanobis_score = term_gau.view(-1,1)\n",
    "        else:\n",
    "            mahalanobis_score = torch.cat((mahalanobis_score, term_gau.view(-1,1)), 0)\n",
    "        total += temp_batch\n",
    "        \n",
    "    mahalanobis_score = mahalanobis_score.view(-1)\n",
    "    feature = feature.view(feature.size(0), -1)\n",
    "    selected_mahal, selected_idx = torch.topk(mahalanobis_score, int(feature.size(0)*frac))\n",
    "    print('Total mahal shape:', mahalanobis_score.shape, 'Selected mahal shape: ', selected_mahal.shape)\n",
    "    selected_feature = torch.index_select(feature, 0, selected_idx.cuda())\n",
    "    new_sample_mean = torch.mean(selected_feature, 0)\n",
    "    \n",
    "    # compute covariance matrix\n",
    "    X = 0\n",
    "    flag = 0\n",
    "    for j in range(selected_feature.size(0)):\n",
    "        temp_feature = selected_feature[j]\n",
    "        temp_feature = temp_feature - new_sample_mean\n",
    "        temp_feature = temp_feature.view(-1,1)\n",
    "        if flag  == 0:\n",
    "            X = temp_feature.transpose(0,1)\n",
    "            flag = 1\n",
    "        else:\n",
    "            X = torch.cat((X, temp_feature.transpose(0,1)),0)\n",
    "    # find inverse            \n",
    "    group_lasso.fit(X.cpu().numpy())\n",
    "    new_sample_cov = group_lasso.covariance_\n",
    "    \n",
    "    return new_sample_mean, new_sample_cov, selected_idx, selected_mahal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single MCD and merge the parameters\n",
      "Total mahal shape: torch.Size([4976]) Selected mahal shape:  torch.Size([3483])\n",
      "Total mahal shape: torch.Size([5087]) Selected mahal shape:  torch.Size([3560])\n",
      "Total mahal shape: torch.Size([4918]) Selected mahal shape:  torch.Size([3442])\n",
      "Total mahal shape: torch.Size([5030]) Selected mahal shape:  torch.Size([3521])\n",
      "Total mahal shape: torch.Size([5028]) Selected mahal shape:  torch.Size([3519])\n",
      "Total mahal shape: torch.Size([5027]) Selected mahal shape:  torch.Size([3518])\n",
      "Total mahal shape: torch.Size([5033]) Selected mahal shape:  torch.Size([3523])\n",
      "Total mahal shape: torch.Size([5005]) Selected mahal shape:  torch.Size([3503])\n",
      "Total mahal shape: torch.Size([4933]) Selected mahal shape:  torch.Size([3453])\n",
      "Total mahal shape: torch.Size([4963]) Selected mahal shape:  torch.Size([3474])\n",
      "Total mahal shape: torch.Size([4976]) Selected mahal shape:  torch.Size([3483])\n",
      "Total mahal shape: torch.Size([5087]) Selected mahal shape:  torch.Size([3560])\n",
      "Total mahal shape: torch.Size([4918]) Selected mahal shape:  torch.Size([3442])\n",
      "Total mahal shape: torch.Size([5030]) Selected mahal shape:  torch.Size([3521])\n",
      "Total mahal shape: torch.Size([5028]) Selected mahal shape:  torch.Size([3519])\n",
      "Total mahal shape: torch.Size([5027]) Selected mahal shape:  torch.Size([3518])\n",
      "Total mahal shape: torch.Size([5033]) Selected mahal shape:  torch.Size([3523])\n",
      "Total mahal shape: torch.Size([5005]) Selected mahal shape:  torch.Size([3503])\n",
      "Total mahal shape: torch.Size([4933]) Selected mahal shape:  torch.Size([3453])\n",
      "Total mahal shape: torch.Size([4963]) Selected mahal shape:  torch.Size([3474])\n",
      "Total mahal shape: torch.Size([4976]) Selected mahal shape:  torch.Size([3483])\n",
      "Total mahal shape: torch.Size([5087]) Selected mahal shape:  torch.Size([3560])\n",
      "Total mahal shape: torch.Size([4918]) Selected mahal shape:  torch.Size([3442])\n",
      "Total mahal shape: torch.Size([5030]) Selected mahal shape:  torch.Size([3521])\n",
      "Total mahal shape: torch.Size([5028]) Selected mahal shape:  torch.Size([3519])\n",
      "Total mahal shape: torch.Size([5027]) Selected mahal shape:  torch.Size([3518])\n",
      "Total mahal shape: torch.Size([5033]) Selected mahal shape:  torch.Size([3523])\n",
      "Total mahal shape: torch.Size([5005]) Selected mahal shape:  torch.Size([3503])\n",
      "Total mahal shape: torch.Size([4933]) Selected mahal shape:  torch.Size([3453])\n",
      "Total mahal shape: torch.Size([4963]) Selected mahal shape:  torch.Size([3474])\n"
     ]
    }
   ],
   "source": [
    "print('Single MCD and merge the parameters')\n",
    "new_sample_mean_list = []\n",
    "new_sample_precision_list = []\n",
    "selected_feature = []\n",
    "layer_selected_index = []\n",
    "total_mahla_layer = []\n",
    "\n",
    "for index in range(num_output):\n",
    "    tmp_selected_idx = []\n",
    "    tmp_mahal_class = []\n",
    "\n",
    "    new_sample_mean = torch.Tensor(config['num_classes'], total_final_feature[index].size(1)).fill_(0).cuda()\n",
    "    \n",
    "    new_covariance = 0\n",
    "    for i in range(config['num_classes']):\n",
    "        index_list = total_label_list[index].eq(i)\n",
    "        temp_feature = total_final_feature[index][index_list.nonzero(), :]\n",
    "        tmp_idx_list = index_list.nonzero().view(-1).detach().cpu()\n",
    "#         print(temp_feature.shape)\n",
    "        temp_feature = temp_feature.view(temp_feature.size(0), -1)\n",
    "        temp_mean, temp_cov, tmp_idx, tmp_mahal = MCD_single(temp_feature.cuda(), sample_mean_list[index][i], sample_precision_list[index])\n",
    "#         print('selcted index for class', i, ':', tmp_idx.shape)\n",
    "        new_sample_mean[i].copy_(temp_mean)\n",
    "        tmp_real_idx = tmp_idx_list[tmp_idx.detach().cpu()]\n",
    "        tmp_selected_idx.extend(tmp_real_idx.tolist())\n",
    "        tmp_mahal_class.append(tmp_mahal)\n",
    "\n",
    "\n",
    "        if i  == 0:\n",
    "            new_covariance = temp_feature.size(0)*temp_cov\n",
    "        else:\n",
    "            new_covariance += temp_feature.size(0)*temp_cov\n",
    "        \n",
    "    layer_selected_index.append(tmp_selected_idx)\n",
    "    total_mahla_layer.append(tmp_mahal_class)\n",
    "            \n",
    "    new_covariance = new_covariance / total_final_feature[index].size(0)\n",
    "    new_precision = scipy.linalg.pinvh(new_covariance)\n",
    "    new_precision = torch.from_numpy(new_precision).float().cuda()\n",
    "    new_sample_mean_list.append(new_sample_mean)\n",
    "    new_sample_precision_list.append(new_precision)\n",
    "\n",
    "G_soft_list = []\n",
    "target_mean = new_sample_mean_list \n",
    "target_precision = new_sample_precision_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mahalanobis distance list for layer 2\n",
    "layer2_mahal = total_mahla_layer[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing mahalanobis distance eigen vs MCD in classwise manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd_mahal0 = -layer2_mahal[3].cpu().detach().numpy()\n",
    "eigen_mahal0 = aa[3].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3521,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcd_mahal0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2043,)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigen_mahal0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511.7668"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(mcd_mahal0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24590.277"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(eigen_mahal0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.069557"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(mcd_mahal0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "647.1175"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(eigen_mahal0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313.20895"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.median(mcd_mahal0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2177.134"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.median(eigen_mahal0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0.,   0.,   2.,  16.,  79., 176., 268., 293., 215., 151., 120.,\n",
       "         85.,  55.,  61.,  34.,  35.,  24.,  26.,  30.,  18.,  11.,  14.,\n",
       "         14.,  18.,   6.,   9.,  21.,   8.,   9.,  16.,  13.,   7.,   5.,\n",
       "         18.,  14.,   5.,   7.,   7.,   9.,   3.,  15.,  11.,   9.,   9.,\n",
       "          2.,   5.,  12.,   6.,   4.,   4.,   5.,   8.,   1.,   2.,   2.,\n",
       "          8.,   3.,   2.,   3.,   6.,   1.,   2.,   2.,   2.,   2.,   3.,\n",
       "          0.,   0.,   3.,   3.,   0.,   0.,   1.,   0.,   1.,   0.,   0.,\n",
       "          2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,\n",
       "          1.]),\n",
       " array([    0.     ,   245.90277,   491.80554,   737.7083 ,   983.6111 ,\n",
       "         1229.5139 ,  1475.4166 ,  1721.3195 ,  1967.2222 ,  2213.125  ,\n",
       "         2459.0278 ,  2704.9304 ,  2950.8333 ,  3196.736  ,  3442.639  ,\n",
       "         3688.5415 ,  3934.4443 ,  4180.347  ,  4426.25   ,  4672.153  ,\n",
       "         4918.0557 ,  5163.958  ,  5409.861  ,  5655.7637 ,  5901.6665 ,\n",
       "         6147.5693 ,  6393.472  ,  6639.375  ,  6885.278  ,  7131.1807 ,\n",
       "         7377.083  ,  7622.986  ,  7868.8887 ,  8114.7915 ,  8360.694  ,\n",
       "         8606.597  ,  8852.5    ,  9098.402  ,  9344.306  ,  9590.208  ,\n",
       "         9836.111  , 10082.014  , 10327.916  , 10573.819  , 10819.722  ,\n",
       "        11065.625  , 11311.527  , 11557.431  , 11803.333  , 12049.236  ,\n",
       "        12295.139  , 12541.041  , 12786.944  , 13032.847  , 13278.75   ,\n",
       "        13524.652  , 13770.556  , 14016.458  , 14262.361  , 14508.264  ,\n",
       "        14754.166  , 15000.069  , 15245.972  , 15491.875  , 15737.777  ,\n",
       "        15983.681  , 16229.583  , 16475.486  , 16721.389  , 16967.291  ,\n",
       "        17213.193  , 17459.098  , 17705.     , 17950.902  , 18196.805  ,\n",
       "        18442.707  , 18688.611  , 18934.514  , 19180.416  , 19426.318  ,\n",
       "        19672.223  , 19918.125  , 20164.027  , 20409.93   , 20655.832  ,\n",
       "        20901.736  , 21147.639  , 21393.541  , 21639.443  , 21885.348  ,\n",
       "        22131.25   , 22377.152  , 22623.055  , 22868.957  , 23114.861  ,\n",
       "        23360.764  , 23606.666  , 23852.568  , 24098.473  , 24344.375  ,\n",
       "        24590.277  ], dtype=float32),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mcd_mahal0, histtype='bar', range=(0, max(eigen_mahal0)), alpha=1, bins=100, ec='k', density=False)\n",
    "plt.hist(eigen_mahal0, histtype='bar', range=(0, max(eigen_mahal0)), alpha=0.3, bins=100, ec='k',density=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
