{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn.covariance\n",
    "import scipy\n",
    "import pdb\n",
    "\n",
    "import data_loader.data_loaders as module_data\n",
    "import loss as module_loss\n",
    "import model.metric as module_metric\n",
    "import model.model as module_arch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import model.model as module_arch\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import cluster\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from parse_config import ConfigParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_file = './hyperparams/multistep/config_cifar10_cce_rn34.json'\n",
    "config_file = './saved/models/cifar10/resnet34/MultiStepLR/CCELoss/sym/60/config_123.json'\n",
    "with open(config_file, 'r') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'cifar10_resnet34_multistep',\n",
       " 'n_gpu': 1,\n",
       " 'seed': 123,\n",
       " 'arch': {'type': 'resnet34', 'args': {'num_classes': 10}},\n",
       " 'num_classes': 10,\n",
       " 'data_loader': {'type': 'CIFAR10DataLoader',\n",
       "  'args': {'data_dir': './dir_to_data',\n",
       "   'batch_size': 128,\n",
       "   'shuffle': True,\n",
       "   'num_batches': 0,\n",
       "   'validation_split': 0,\n",
       "   'num_workers': 8,\n",
       "   'pin_memory': True}},\n",
       " 'optimizer': {'type': 'SGD',\n",
       "  'args': {'lr': 0.02, 'momentum': 0.9, 'weight_decay': 0.001}},\n",
       " 'train_loss': {'type': 'CCELoss'},\n",
       " 'val_loss': 'CrossEntropyLoss',\n",
       " 'metrics': ['my_metric', 'my_metric2'],\n",
       " 'lr_scheduler': {'type': 'MultiStepLR',\n",
       "  'args': {'milestones': [40, 80], 'gamma': 0.01}},\n",
       " 'trainer': {'epochs': 120,\n",
       "  'warmup': 0,\n",
       "  'save_dir': 'saved/',\n",
       "  'save_period': 1,\n",
       "  'verbosity': 2,\n",
       "  'label_dir': 'saved/',\n",
       "  'monitor': 'max test_my_metric',\n",
       "  'early_stop': 2000,\n",
       "  'tensorboard': False,\n",
       "  'mlflow': True,\n",
       "  '_percent': 'Percentage of noise',\n",
       "  'percent': 0.6,\n",
       "  '_begin': 'When to begin updating labels',\n",
       "  'begin': 0,\n",
       "  '_asym': 'symmetric noise if false',\n",
       "  'asym': False}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config['trainer']['percent'] = 0.4\n",
    "# config['trainer']['asym'] = False\n",
    "# config['train_loss']['type'] = 'GCELoss'\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_path = './saved/models/cifar10/resnet34/MultiStepLR/CCELoss/sym/60/model_best123.pth'\n",
    "base_model = getattr(module_arch, config[\"arch\"]['type'])()\n",
    "checkpoint = torch.load(resume_path)\n",
    "state_dict = checkpoint['state_dict']\n",
    "base_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Train: 50000 Val: 0\n"
     ]
    }
   ],
   "source": [
    "# set seed\n",
    "random.seed(config['seed'])\n",
    "torch.manual_seed(config['seed'])\n",
    "torch.cuda.manual_seed_all(config['seed'])\n",
    "torch.backends.cudnn.deterministic = True\n",
    "np.random.seed(config['seed'])\n",
    "\n",
    "data_loader = getattr(module_data, config['data_loader']['type'])(\n",
    "    config['data_loader']['args']['data_dir'],\n",
    "    batch_size= 100,\n",
    "    shuffle=config['data_loader']['args']['shuffle'],\n",
    "    validation_split=0.0,\n",
    "    num_batches=config['data_loader']['args']['num_batches'],\n",
    "    training=True,\n",
    "    num_workers=config['data_loader']['args']['num_workers'],\n",
    "    pin_memory=config['data_loader']['args']['pin_memory'],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "if hasattr(data_loader.dataset, 'num_raw_example'):\n",
    "    num_examp = data_loader.dataset.num_raw_example\n",
    "else:\n",
    "    num_examp = len(data_loader.dataset)\n",
    "\n",
    "critenrion = nn.CrossEntropyLoss()\n",
    "\n",
    "# criterion = getattr(module_loss, 'GCELoss')(q=config['train_loss']['args']['q'],\n",
    "#                                                      k=config['train_loss']['args']['k'],\n",
    "#                                                      truncated=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Represent(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(Represent, self).__init__()\n",
    "        self.conv1 = base_model.conv1\n",
    "        self.bn1 = base_model.bn1\n",
    "        self.layer1 = base_model.layer1\n",
    "        self.layer2 = base_model.layer2\n",
    "        self.layer3 = base_model.layer3\n",
    "        self.layer4 = base_model.layer4\n",
    "        self.linear = base_model.linear\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        y = out.view(out.size(0), -1)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    #Feature Extractting\n",
    "    def feature_list(self, x):\n",
    "        output_list = []\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        for name, module in self.layer1._modules.items():\n",
    "            out = module(out)\n",
    "        for name, module in self.layer2._modules.items():\n",
    "            out = module(out)\n",
    "        for name, module in self.layer3._modules.items():\n",
    "            out = module(out)\n",
    "        for name, module in self.layer4._modules.items():\n",
    "            out = module(out)\n",
    "            output_list.append(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        y = self.linear(out)\n",
    "        return y, output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Represent(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNoisy_list = np.empty((0,))\n",
    "isFalse_list = np.empty((0,))\n",
    "label_list = np.empty((0,))\n",
    "gt_list = np.empty((0,))\n",
    "conf_list = np.empty((0,))\n",
    "loss_list = np.empty((0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_label = data_loader.dataset.train_labels\n",
    "gt_label = data_loader.dataset.train_labels_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise rate:  0.54082\n"
     ]
    }
   ],
   "source": [
    "#Noise rate check\n",
    "tmp = 0\n",
    "for i in range(len(gt_label)):\n",
    "    if noisy_label[i] != gt_label[i]:\n",
    "        tmp += 1\n",
    "print('Noise rate: ', tmp/len(gt_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNAES / K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:29<00:00, 17.17it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "loss = 0\n",
    "\n",
    "with tqdm(data_loader) as progress:\n",
    "    for batch_idx, (data, label, index, label_gt) in enumerate(progress):\n",
    "        data = data.to(device)\n",
    "        label, label_gt = label.long().to(device), label_gt.long().to(device)\n",
    "        output = model(data)\n",
    "        _,prediction = base_model(data)\n",
    "        loss = torch.nn.CrossEntropyLoss(reduction='none')(prediction, label)\n",
    "        confidence, _ = torch.max(torch.nn.functional.softmax(prediction, dim=1), dim=1)\n",
    "        isNoisy = label != label_gt\n",
    "        \n",
    "        gt_list = np.concatenate((gt_list, label_gt.cpu()))\n",
    "        label_list = np.concatenate((label_list, label.cpu()))\n",
    "        isNoisy_list = np.concatenate((isNoisy_list, isNoisy.cpu()))\n",
    "        conf_list = np.concatenate((conf_list, confidence.detach().cpu()))\n",
    "        loss_list = np.concatenate((loss_list, loss.detach().cpu()))\n",
    "        if batch_idx == 0:\n",
    "            out_list = output.detach().cpu()\n",
    "        else:\n",
    "            out_list = np.concatenate((out_list, output.detach().cpu()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54082"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check noisy rate\n",
    "isNoisy_list.sum()/len(data_loader.dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_singular_value_vector(label_list, out_list):\n",
    "    \n",
    "    singular_dict = {}\n",
    "    v_ortho_dict = {}\n",
    "    \n",
    "    for index in np.unique(label_list):\n",
    "        u, s, v = np.linalg.svd(out_list[label_list==index])\n",
    "        singular_dict[index] = s[0] / s[1]\n",
    "        v_ortho_dict[index] = torch.from_numpy(v[:2])\n",
    "\n",
    "    return singular_dict, v_ortho_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singular_label(v_ortho_dict, model_represents, label):\n",
    "    \n",
    "    model_represents = torch.from_numpy(model_represents).to(device)\n",
    "    sing_lbl = torch.zeros(model_represents.shape[0]) \n",
    "    sin_score_lbl = torch.zeros(model_represents.shape[0])\n",
    "    \n",
    "    for i, data in enumerate(model_represents):\n",
    "        sin_score_lbl[i] = torch.dot(v_ortho_dict[label[i]][0], data).abs() - torch.dot(v_ortho_dict[label[i]][1], data).abs()\n",
    "        if torch.dot(v_ortho_dict[label[i]][0], data).abs() < torch.dot(v_ortho_dict[label[i]][1], data).abs():\n",
    "            sing_lbl[i] = 1\n",
    "        \n",
    "    return sing_lbl, sin_score_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "singular_dict, v_ortho_dict = get_singular_value_vector(label_list, out_list)\n",
    "\n",
    "for key in v_ortho_dict.keys():\n",
    "    v_ortho_dict[key] = v_ortho_dict[key].to(device)\n",
    "\n",
    "sing_lbl, sin_score_lbl = singular_label(v_ortho_dict, out_list, label_list)\n",
    "kmeans = cluster.KMeans(n_clusters=2, random_state=0).fit(loss_list.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24403, 0.90325, 0.96006, 0.91269, 0.93444, 0.90325]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_statistics(isNoisy_list, predict):\n",
    "    r_stats = []\n",
    "    \n",
    "    tp = (isNoisy_list[predict==0]==0).sum()\n",
    "    tn = isNoisy_list[predict==1].sum()\n",
    "    fp = isNoisy_list.sum() - tn\n",
    "    fn = ((isNoisy_list.shape - isNoisy_list.sum()) - tp).item()\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    sel_samples = int(fp + tp)\n",
    "    frac_clean = tp / (fp + tp)\n",
    "\n",
    "    r_stats.extend([sel_samples, round(precision, 5), round(recall, 5), round(specificity, 5), round(accuracy, 5), round(frac_clean, 5)])\n",
    "    \n",
    "    return r_stats\n",
    "\n",
    "return_statistics(isNoisy_list, sing_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_summary(name, stat_list):\n",
    "    print('Dataset: {}, Net: {}, Noise{}_{}, Loss: {}'\n",
    "      .format(config['data_loader']['type'], config['arch']['type'], config['trainer']['asym'], config['trainer']['percent'], config['train_loss']['type']))\n",
    "    \n",
    "    print(\"=\"*50, name , \"=\"*50)\n",
    "\n",
    "    print('Selected samples by {}: {} \\nPrecision: {} \\nRecall: {} \\nSpecificity: {}\\nAccuracy: {} \\nFraction of clean samples/selected samples: {}'\n",
    "                  .format(name, stat_list[0], stat_list[1], stat_list[2], stat_list[3], stat_list[4], stat_list[5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CIFAR10DataLoader, Net: resnet34, NoiseFalse_0.6, Loss: CCELoss\n",
      "================================================== K-means Clustering ==================================================\n",
      "Selected samples by K-means Clustering: 21252 \n",
      "Precision: 0.96786 \n",
      "Recall: 0.8959 \n",
      "Specificity: 0.97474\n",
      "Accuracy: 0.93854 \n",
      "Fraction of clean samples/selected samples: 0.96786\n"
     ]
    }
   ],
   "source": [
    "k_mean_cluster0 = np.mean(loss_list[kmeans.labels_ == 0])\n",
    "k_mean_cluster1 = np.mean(loss_list[kmeans.labels_ == 1])\n",
    "\n",
    "k_compare_label = kmeans.labels_ if k_mean_cluster0 < k_mean_cluster1 else (1 - kmeans.labels_)\n",
    "\n",
    "k_mean_stat = return_statistics(isNoisy_list, k_compare_label) # Selected samples, precision, recall, specificity, accuracy, fraction of clean samples\n",
    "stat_summary('K-means Clustering', k_mean_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21252, 0.96786, 0.8959, 0.97474, 0.93854, 0.96786]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_mean_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CIFAR10DataLoader, Net: resnet34, NoiseFalse_0.6, Loss: CCELoss\n",
      "================================================== FNAES ==================================================\n",
      "Selected samples by FNAES: 24403 \n",
      "Precision: 0.90325 \n",
      "Recall: 0.96006 \n",
      "Specificity: 0.91269\n",
      "Accuracy: 0.93444 \n",
      "Fraction of clean samples/selected samples: 0.90325\n"
     ]
    }
   ],
   "source": [
    "fnaes_stat = return_statistics(isNoisy_list, sing_lbl)\n",
    "stat_summary('FNAES', fnaes_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get raw data\n",
    "\n",
    "for batch_idx, (data, target, index, label_gt) in enumerate(data_loader):\n",
    "    data, target, label_gt = data.cuda(), target.cuda(), label_gt.cuda()\n",
    "    if batch_idx == 0:\n",
    "        total_data = data\n",
    "        total_target = target\n",
    "        total_label_gt = label_gt\n",
    "    else:\n",
    "        total_data = torch.cat((total_data, data), 0)\n",
    "        total_target = torch.cat((total_target, target), 0)\n",
    "        total_label_gt = torch.cat((total_label_gt, label_gt), 0)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise rate:  0.54082\n"
     ]
    }
   ],
   "source": [
    "#Noise rate check\n",
    "tmp = 0\n",
    "for i in range(len(total_label_gt)):\n",
    "    if total_target[i] != total_label_gt[i]:\n",
    "        tmp += 1\n",
    "print('Noise rate: ', tmp/len(total_label_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-2d1080d009e6>:3: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  temp_x = Variable(temp_x, volatile=True)\n",
      "<ipython-input-23-2d1080d009e6>:12: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data = Variable(data, volatile=True)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "temp_x = torch.rand(2,3,32,32).cuda()\n",
    "temp_x = Variable(temp_x, volatile=True)\n",
    "temp_list = model.feature_list(temp_x)[1]\n",
    "num_output = len(temp_list) # Number of layers that extracts feature\n",
    "total_final_feature = [0]*num_output #Extracted Features\n",
    "total = 0\n",
    "batch_size = 100\n",
    "\n",
    "for data_index in range(int(np.floor(total_data.size(0)/batch_size))):\n",
    "    data = total_data[total : total + batch_size]\n",
    "    data = Variable(data, volatile=True)\n",
    "\n",
    "    _, out_features = model.feature_list(data)\n",
    "    for i in range(num_output):\n",
    "        out_features[i] = out_features[i].view(out_features[i].size(0), out_features[i].size(1), -1)\n",
    "        out_features[i] = torch.mean(out_features[i].data, 2)\n",
    "        if total == 0:\n",
    "            total_final_feature[i] = out_features[i].cpu().clone()\n",
    "        else:\n",
    "            total_final_feature[i] = torch.cat((total_final_feature[i], out_features[i].cpu().clone()), 0)\n",
    "    total += batch_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 512])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_final_feature[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Initailzation of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Sample Mean\n",
    "def random_sample_mean(feature, total_label, num_classes):\n",
    "    \n",
    "    group_lasso = sklearn.covariance.EmpiricalCovariance(assume_centered = False)    \n",
    "    new_feature, fraction_list = [], []\n",
    "    frac = 0.7\n",
    "    sample_mean_per_class = torch.Tensor(num_classes, feature.size(1)).fill_(0).cuda()\n",
    "    total_label = total_label.cuda()\n",
    "\n",
    "    \n",
    "    total_selected_list = []\n",
    "    for i in range(num_classes):\n",
    "        index_list = total_label.eq(i)\n",
    "        temp_feature = feature[index_list.nonzero(), :]\n",
    "        temp_feature = temp_feature.view(temp_feature.size(0), -1)\n",
    "        shuffler_idx = torch.randperm(temp_feature.size(0))\n",
    "        index = shuffler_idx[:int(temp_feature.size(0)*frac)]\n",
    "        fraction_list.append(int(temp_feature.size(0)*frac))\n",
    "        total_selected_list.append(index_list.nonzero()[index.cuda()])\n",
    "\n",
    "        selected_feature = torch.index_select(temp_feature, 0, index.cuda())\n",
    "        new_feature.append(selected_feature)\n",
    "        sample_mean_per_class[i].copy_(torch.mean(selected_feature, 0))\n",
    "    \n",
    "    total_covariance = 0\n",
    "    for i in range(num_classes):\n",
    "        flag = 0\n",
    "        X = 0\n",
    "        for j in range(fraction_list[i]):\n",
    "            temp_feature = new_feature[i][j]\n",
    "            temp_feature = temp_feature - sample_mean_per_class[i]\n",
    "            temp_feature = temp_feature.view(-1,1)\n",
    "            if flag  == 0:\n",
    "                X = temp_feature.transpose(0,1)\n",
    "                flag = 1\n",
    "            else:\n",
    "                X = torch.cat((X,temp_feature.transpose(0,1)),0)\n",
    "            # find inverse            \n",
    "        group_lasso.fit(X.cpu().numpy())\n",
    "        inv_sample_conv = group_lasso.covariance_\n",
    "        inv_sample_conv = torch.from_numpy(inv_sample_conv).float().cuda()\n",
    "        if i == 0:\n",
    "            total_covariance = inv_sample_conv*fraction_list[i]\n",
    "        else:\n",
    "            total_covariance += inv_sample_conv*fraction_list[i]\n",
    "        total_covariance = total_covariance/sum(fraction_list)\n",
    "    new_precision = scipy.linalg.pinvh(total_covariance.cpu().numpy())\n",
    "    new_precision = torch.from_numpy(new_precision).float().cuda()\n",
    "    \n",
    "    return sample_mean_per_class, new_precision, total_selected_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Sample Mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-3867dc7d9129>:14: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370172916/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  temp_feature = feature[index_list.nonzero(), :]\n"
     ]
    }
   ],
   "source": [
    "print('Random Sample Mean')\n",
    "sample_mean_list, sample_precision_list = [], []\n",
    "total_label_list = [total_target for i in range(num_output)]\n",
    "\n",
    "for index in range(num_output):\n",
    "    sample_mean, sample_precision, _ = random_sample_mean(total_final_feature[index].cuda(), total_label_list[index].cuda(), config['num_classes'])\n",
    "    sample_mean_list.append(sample_mean)\n",
    "    sample_precision_list.append(sample_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean for each entity corresponding to feature vector\n",
    "sample_mean_list[2][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Covariance determinent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MCD single\n",
    "def MCD_single(feature, sample_mean, inverse_covariance):\n",
    "    group_lasso = sklearn.covariance.EmpiricalCovariance(assume_centered=False)\n",
    "    temp_batch = 100\n",
    "    total, mahalanobis_score = 0, 0\n",
    "    frac = 0.7 #fraction N_c+d+1 / 2\n",
    "    for data_index in range(int(np.ceil(feature.size(0)/temp_batch))):\n",
    "        temp_feature = feature[total : total + temp_batch].cuda()        \n",
    "        gaussian_score = 0\n",
    "        batch_sample_mean = sample_mean\n",
    "        zero_f = temp_feature - batch_sample_mean\n",
    "        term_gau = -0.5*torch.mm(torch.mm(zero_f, inverse_covariance), zero_f.t()).diag()\n",
    "        # concat data\n",
    "        if total == 0:\n",
    "            mahalanobis_score = term_gau.view(-1,1)\n",
    "        else:\n",
    "            mahalanobis_score = torch.cat((mahalanobis_score, term_gau.view(-1,1)), 0)\n",
    "        total += temp_batch\n",
    "        \n",
    "    mahalanobis_score = mahalanobis_score.view(-1)\n",
    "    feature = feature.view(feature.size(0), -1)\n",
    "    _, selected_idx = torch.topk(mahalanobis_score, int(feature.size(0)*frac)) # 전체 class에서 selected index\n",
    "    selected_feature = torch.index_select(feature, 0, selected_idx.cuda())\n",
    "    new_sample_mean = torch.mean(selected_feature, 0)\n",
    "    \n",
    "    # compute covariance matrix\n",
    "    X = 0\n",
    "    flag = 0\n",
    "    for j in range(selected_feature.size(0)):\n",
    "        temp_feature = selected_feature[j]\n",
    "        temp_feature = temp_feature - new_sample_mean\n",
    "        temp_feature = temp_feature.view(-1,1)\n",
    "        if flag  == 0:\n",
    "            X = temp_feature.transpose(0,1)\n",
    "            flag = 1\n",
    "        else:\n",
    "            X = torch.cat((X, temp_feature.transpose(0,1)),0)\n",
    "    # find inverse            \n",
    "    group_lasso.fit(X.cpu().numpy())\n",
    "    new_sample_cov = group_lasso.covariance_\n",
    "    \n",
    "    return new_sample_mean, new_sample_cov, selected_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single MCD and merge the parameters\n",
      "torch.Size([5042, 1, 512])\n",
      "selcted index for class 0 : torch.Size([3529])\n",
      "torch.Size([5081, 1, 512])\n",
      "selcted index for class 1 : torch.Size([3556])\n",
      "torch.Size([4887, 1, 512])\n",
      "selcted index for class 2 : torch.Size([3420])\n",
      "torch.Size([5071, 1, 512])\n",
      "selcted index for class 3 : torch.Size([3549])\n",
      "torch.Size([4977, 1, 512])\n",
      "selcted index for class 4 : torch.Size([3483])\n",
      "torch.Size([5026, 1, 512])\n",
      "selcted index for class 5 : torch.Size([3518])\n",
      "torch.Size([4978, 1, 512])\n",
      "selcted index for class 6 : torch.Size([3484])\n",
      "torch.Size([4977, 1, 512])\n",
      "selcted index for class 7 : torch.Size([3483])\n",
      "torch.Size([4965, 1, 512])\n",
      "selcted index for class 8 : torch.Size([3475])\n",
      "torch.Size([4996, 1, 512])\n",
      "selcted index for class 9 : torch.Size([3497])\n",
      "torch.Size([5042, 1, 512])\n",
      "selcted index for class 0 : torch.Size([3529])\n",
      "torch.Size([5081, 1, 512])\n",
      "selcted index for class 1 : torch.Size([3556])\n",
      "torch.Size([4887, 1, 512])\n",
      "selcted index for class 2 : torch.Size([3420])\n",
      "torch.Size([5071, 1, 512])\n",
      "selcted index for class 3 : torch.Size([3549])\n",
      "torch.Size([4977, 1, 512])\n",
      "selcted index for class 4 : torch.Size([3483])\n",
      "torch.Size([5026, 1, 512])\n",
      "selcted index for class 5 : torch.Size([3518])\n",
      "torch.Size([4978, 1, 512])\n",
      "selcted index for class 6 : torch.Size([3484])\n",
      "torch.Size([4977, 1, 512])\n",
      "selcted index for class 7 : torch.Size([3483])\n",
      "torch.Size([4965, 1, 512])\n",
      "selcted index for class 8 : torch.Size([3475])\n",
      "torch.Size([4996, 1, 512])\n",
      "selcted index for class 9 : torch.Size([3497])\n",
      "torch.Size([5042, 1, 512])\n",
      "selcted index for class 0 : torch.Size([3529])\n",
      "torch.Size([5081, 1, 512])\n",
      "selcted index for class 1 : torch.Size([3556])\n",
      "torch.Size([4887, 1, 512])\n",
      "selcted index for class 2 : torch.Size([3420])\n",
      "torch.Size([5071, 1, 512])\n",
      "selcted index for class 3 : torch.Size([3549])\n",
      "torch.Size([4977, 1, 512])\n",
      "selcted index for class 4 : torch.Size([3483])\n",
      "torch.Size([5026, 1, 512])\n",
      "selcted index for class 5 : torch.Size([3518])\n",
      "torch.Size([4978, 1, 512])\n",
      "selcted index for class 6 : torch.Size([3484])\n",
      "torch.Size([4977, 1, 512])\n",
      "selcted index for class 7 : torch.Size([3483])\n",
      "torch.Size([4965, 1, 512])\n",
      "selcted index for class 8 : torch.Size([3475])\n",
      "torch.Size([4996, 1, 512])\n",
      "selcted index for class 9 : torch.Size([3497])\n"
     ]
    }
   ],
   "source": [
    "print('Single MCD and merge the parameters')\n",
    "new_sample_mean_list = []\n",
    "new_sample_precision_list = []\n",
    "selected_feature = []\n",
    "layer_selected_index = []\n",
    "for index in range(num_output):\n",
    "    tmp_selected_idx = []\n",
    "\n",
    "    new_sample_mean = torch.Tensor(config['num_classes'], total_final_feature[index].size(1)).fill_(0).cuda()\n",
    "    new_covariance = 0\n",
    "    for i in range(config['num_classes']):\n",
    "        index_list = total_label_list[index].eq(i) # index corresponding to each class [50000]\n",
    "        temp_feature = total_final_feature[index][index_list.nonzero(), :] # feature corresponding to index_list [4972,512]\n",
    "        tmp_idx_list = index_list.nonzero().view(-1).detach().cpu() # original index number of selected feature [4972]\n",
    "        print(temp_feature.shape)\n",
    "        temp_feature = temp_feature.view(temp_feature.size(0), -1)\n",
    "        temp_mean, temp_cov, tmp_idx = MCD_single(temp_feature.cuda(), sample_mean_list[index][i], sample_precision_list[index]) # tmp_idx = MCD에서 뽑은거 [3480]\n",
    "        print('selcted index for class', i, ':', tmp_idx.shape)\n",
    "        new_sample_mean[i].copy_(temp_mean)\n",
    "        tmp_real_idx = tmp_idx_list[tmp_idx.detach().cpu()]\n",
    "        tmp_selected_idx.extend(tmp_real_idx.tolist())\n",
    "\n",
    "        if i  == 0:\n",
    "            new_covariance = temp_feature.size(0)*temp_cov\n",
    "        else:\n",
    "            new_covariance += temp_feature.size(0)*temp_cov\n",
    "        \n",
    "    layer_selected_index.append(tmp_selected_idx)\n",
    "            \n",
    "    new_covariance = new_covariance / total_final_feature[index].size(0)\n",
    "    new_precision = scipy.linalg.pinvh(new_covariance)\n",
    "    new_precision = torch.from_numpy(new_precision).float().cuda()\n",
    "    new_sample_mean_list.append(new_sample_mean)\n",
    "    new_sample_precision_list.append(new_precision)\n",
    "\n",
    "G_soft_list = []\n",
    "target_mean = new_sample_mean_list \n",
    "target_precision = new_sample_precision_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "34994\n",
      "tensor([39591, 20623, 29083,  ..., 49402,  1279,  5468])\n"
     ]
    }
   ],
   "source": [
    "new_sample_mean_list[0].shape\n",
    "\n",
    "print(len(new_sample_mean_list))\n",
    "print(len(tmp_selected_idx))\n",
    "print(tmp_real_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34994"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layer_selected_index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34994\n",
      "34994\n",
      "34994\n"
     ]
    }
   ],
   "source": [
    "layer4_0 = layer_selected_index[0]\n",
    "layer4_1 = layer_selected_index[1]\n",
    "layer4_2 = layer_selected_index[2]\n",
    "\n",
    "print(len(layer4_0))\n",
    "print(len(layer4_1))\n",
    "print(len(layer4_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Check for same index\n",
    "import collections\n",
    "for i in range(len(layer_selected_index)):\n",
    "    print(len([item for item, count in collections.Counter(layer_selected_index[i]).items() if count > 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected data Difference \n",
      "4_0 vs 4_1: 30602 \n",
      "4_1 vs 4_2: 33164 \n",
      "4_0 vs 4_2: 29752\n"
     ]
    }
   ],
   "source": [
    "print('Selected data Difference \\n4_0 vs 4_1: {} \\n4_1 vs 4_2: {} \\n4_0 vs 4_2: {}'\n",
    "      .format(len(set(layer4_0) & set(layer4_1)), len(set(layer4_1) & set(layer4_2)), len(set(layer4_0) & set(layer4_2))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_path = './saved' \n",
    "tmp_asym = 'asym' if config['trainer']['asym'] else 'sym'\n",
    "data_name, net_fam = config['name'].split('_')[0], config['name'].split('_')[1]\n",
    "\n",
    "if not os.path.isdir(saved_path):\n",
    "    os.mkdir(saved_path)\n",
    "next_path = os.path.join(saved_path, 'mahalanobis')\n",
    "if not os.path.isdir(next_path):\n",
    "    os.mkdir(next_path)\n",
    "next_path = os.path.join(next_path, data_name)\n",
    "if not os.path.isdir(next_path):\n",
    "    os.mkdir(next_path)\n",
    "next_path = os.path.join(next_path, net_fam)\n",
    "if not os.path.isdir(next_path):\n",
    "    os.mkdir(next_path)\n",
    "next_path = os.path.join(next_path, config['lr_scheduler']['type'])\n",
    "if not os.path.isdir(next_path):\n",
    "    os.mkdir(next_path)\n",
    "next_path = os.path.join(next_path, config['train_loss']['type'])\n",
    "if not os.path.isdir(next_path):\n",
    "    os.mkdir(next_path)\n",
    "next_path = os.path.join(next_path, tmp_asym)\n",
    "if not os.path.isdir(next_path):\n",
    "    os.mkdir(next_path)\n",
    "file_root = os.path.join(next_path, str(config['trainer']['percent']))\n",
    "if not os.path.isdir(file_root):\n",
    "    os.mkdir(file_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save output_feature, target_noise, label_gt\n",
    "for i in range(num_output):\n",
    "    file_name_data = '%s/%s_feature_4_%s.npy' % (file_root, data_name, str(i))\n",
    "    total_feature = total_final_feature[i].numpy()\n",
    "    np.save(file_name_data , total_feature)\n",
    "\n",
    "file_name_label = '%s/%s_target_noise.npy' % (file_root, data_name)\n",
    "np.save(file_name_label, total_target.detach().cpu())\n",
    "\n",
    "file_name_gt = '%s/%s_label_gt.npy' % (file_root, data_name)\n",
    "np.save(file_name_gt, total_label_gt.detach().cpu())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34994"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layer_selected_index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "50000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "#Generate predicted noise index(Unselected)\n",
    "\n",
    "# layer_seelcted_index[0]  4_0 layer에서 mahalanobis 기준 뽑힌거\n",
    "total_index = [i for i in range(len(total_target))]\n",
    "len(total_index)\n",
    "total_index[-1]\n",
    "\n",
    "predicted_noise_layer = [] # Unselcted 0.3 중에서 noise인지 아닌지를 나타내는 것\n",
    "layer_unselected_index = []\n",
    "\n",
    "for layer in layer_selected_index:\n",
    "    tmpp = set(total_index) - set(layer)\n",
    "    layer_unselected_index.append(list(tmpp))\n",
    "\n",
    "print(len(layer_unselected_index[0]) + len(layer_selected_index[0]))\n",
    "print(len(layer_unselected_index[1]) + len(layer_selected_index[1]))\n",
    "print(len(layer_unselected_index[2]) + len(layer_selected_index[2]))\n",
    "\n",
    "for layer in layer_unselected_index:\n",
    "    tmpp_noisy = []\n",
    "    num_noisy = 0\n",
    "    for i in layer:\n",
    "        if total_target[i] != total_label_gt[i]:\n",
    "            num_noisy += 1 \n",
    "            tmpp_noisy.append(1)\n",
    "        else:\n",
    "            tmpp_noisy.append(0)\n",
    "    predicted_noise_layer.append(tmpp_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CIFAR10DataLoader, Net: resnet34, NoiseFalse_0.6, Loss: CCELoss\n",
      "================================================== Mahalanobis Distance ==================================================\n",
      "layer4_0 \n",
      "Selected samples by Mahalanobis distance: 34994 \n",
      "Fraction of clean samples/selected samples: 0.4786820597816769\n",
      "18243\n",
      "layer4_1 \n",
      "Selected samples by Mahalanobis distance: 34994 \n",
      "Fraction of clean samples/selected samples: 0.4853117677316111\n",
      "18011\n",
      "layer4_2 \n",
      "Selected samples by Mahalanobis distance: 34994 \n",
      "Fraction of clean samples/selected samples: 0.48539749671372234\n",
      "18008\n",
      "====================================================================================================\n",
      "================================================== Mahalanobis Distance ==================================================\n"
     ]
    }
   ],
   "source": [
    "print('Dataset: {}, Net: {}, Noise{}_{}, Loss: {}'\n",
    "      .format(config['data_loader']['type'], config['arch']['type'], config['trainer']['asym'], config['trainer']['percent'], config['train_loss']['type']))\n",
    "print(\"=\"*50, 'Mahalanobis Distance', \"=\"*50)\n",
    "\n",
    "flag = 0\n",
    "predicted_clean_layer = []\n",
    "\n",
    "for layer in layer_selected_index:\n",
    "    tmp_noisy = []\n",
    "    num_noisy = 0\n",
    "    for i in layer:\n",
    "        if total_target[i] != total_label_gt[i]:\n",
    "            num_noisy +=1 \n",
    "            tmp_noisy.append(1)\n",
    "        else:\n",
    "            tmp_noisy.append(0)\n",
    "    print('layer4_{} \\nSelected samples by Mahalanobis distance: {} \\nFraction of clean samples/selected samples: {}'\n",
    "          .format(flag, len(layer), 1-(num_noisy/len(layer))))\n",
    "    print(num_noisy)\n",
    "    flag += 1\n",
    "    predicted_clean_layer.append(tmp_noisy)\n",
    "# config['trainer']['percent']\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"=\"*50, 'Mahalanobis Distance', \"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive class = Clean / Negative Class = Noise\n",
    "recall, specificity, precision, accuracy, frac_clean, sel_samples = [], [], [], [], [], []\n",
    "\n",
    "for i in range(len(predicted_clean_layer)):\n",
    "\n",
    "    tn = sum(predicted_noise_layer[i])\n",
    "    fp = sum(predicted_clean_layer[i])\n",
    "    tp = len(predicted_clean_layer[i]) - fp\n",
    "    fn = len(predicted_noise_layer[i]) - tn\n",
    "    \n",
    "    frac_clean.append( round(tp / (tp + fp), 5))\n",
    "    recall.append(round(tp / (tp + fn), 5))\n",
    "    precision.append(round(tp / (tp + fp), 5))\n",
    "    specificity.append(round(tn / (tn + fp), 5))\n",
    "    accuracy.append(round((tp + tn) / (tp + tn + fp + fn), 5))\n",
    "    sel_samples.append(tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall, specificity, precision, accuracy, frac_clean, sel_samples = [], [], [], [], [], []\n",
    "\n",
    "# for i in range(len(predicted_clean_layer)):\n",
    "\n",
    "#     tp, fn = sum(predicted_noise_layer[i]), sum(predicted_clean_layer[i])\n",
    "#     fp, tn = len(predicted_noise_layer[i]) - tp, len(predicted_clean_layer[i]) - fn\n",
    "\n",
    "#     frac_clean.append( round(tn / (fn + tn), 5))\n",
    "#     recall.append(round(tp / (tp + fn), 5))\n",
    "#     precision.append(round(tp / (tp + fp), 5))\n",
    "#     specificity.append(round(tn / (tn + fp), 5))\n",
    "#     accuracy.append(round((tp + tn) / (tp + tn + fp + fn), 5))\n",
    "#     sel_samples.append(fn + tn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34994, 34994, 34994]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.47868, 0.48531, 0.4854]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7296, 0.73971, 0.73984]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.47868, 0.48531, 0.4854]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32536, 0.33394, 0.33405]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_metric(sel_samples, precision, recall, specificity, accuracy, frac_clean):\n",
    "    print('Dataset: {}, Net: {}, Noise{}_{}, Loss: {}'\n",
    "      .format(config['data_loader']['type'], config['arch']['type'], config['trainer']['asym'], config['trainer']['percent'], config['train_loss']['type']))\n",
    "    print(\"=\"*50, 'Mahalanobis Distance', \"=\"*50)\n",
    "    \n",
    "    if len(recall) > 1:\n",
    "        for i in range(len(recall)):\n",
    "            print('layer4_{} \\nSelected samples by Mahalanobis distance: {} \\nPrecision: {} \\nRecall: {} \\nSpecificity: {}\\nAccuracy: {} \\nFraction of clean samples/selected samples: {}'\n",
    "                  .format(i, sel_samples[i], precision[i], recall[i], specificity[i], accuracy[i], frac_clean[i]))\n",
    "    else:\n",
    "        print('layer4_{} \\nSelected samples by Mahalanobis distance: {} \\nPrecision: {} \\nRecall: {} \\nSpecificity: {}\\nAccuracy: {} \\nFraction of clean samples/selected samples: {}'\n",
    "                  .format(sel_samples, precision, recall, specificity, accuracy, frac_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CIFAR10DataLoader, Net: resnet34, NoiseFalse_0.6, Loss: CCELoss\n",
      "================================================== Mahalanobis Distance ==================================================\n",
      "layer4_0 \n",
      "Selected samples by Mahalanobis distance: 34994 \n",
      "Precision: 0.47868 \n",
      "Recall: 0.7296 \n",
      "Specificity: 0.32536\n",
      "Accuracy: 0.51098 \n",
      "Fraction of clean samples/selected samples: 0.47868\n",
      "layer4_1 \n",
      "Selected samples by Mahalanobis distance: 34994 \n",
      "Precision: 0.48531 \n",
      "Recall: 0.73971 \n",
      "Specificity: 0.33394\n",
      "Accuracy: 0.52026 \n",
      "Fraction of clean samples/selected samples: 0.48531\n",
      "layer4_2 \n",
      "Selected samples by Mahalanobis distance: 34994 \n",
      "Precision: 0.4854 \n",
      "Recall: 0.73984 \n",
      "Specificity: 0.33405\n",
      "Accuracy: 0.52038 \n",
      "Fraction of clean samples/selected samples: 0.4854\n"
     ]
    }
   ],
   "source": [
    "report_metric(sel_samples, precision, recall, specificity, accuracy, frac_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Metric    MCD 0    MCD 1    MCD 2          CLK         SAME\n",
      "0  Sel Samples    34994    34994    34994  21252.00000  24403.00000\n",
      "1    Precision  0.47868  0.48531   0.4854      0.96786      0.90325\n",
      "2       Recall   0.7296  0.73971  0.73984      0.89590      0.96006\n",
      "3  Specificity  0.32536  0.33394  0.33405      0.97474      0.91269\n",
      "4     Accuracy  0.51098  0.52026  0.52038      0.93854      0.93444\n",
      "5     Fraction  0.47868  0.48531   0.4854      0.96786      0.90325\n",
      "./saved/mahalanobis/cifar10/resnet34/MultiStepLR/CCELoss/sym/0.6\n"
     ]
    }
   ],
   "source": [
    "# Save as txt\n",
    "df = pd.DataFrame(columns = ['MCD 0', 'MCD 1', 'MCD 2'])\n",
    "\n",
    "df.loc[len(df)] = sel_samples\n",
    "df.loc[len(df)] = precision\n",
    "df.loc[len(df)] = recall\n",
    "df.loc[len(df)] = specificity\n",
    "df.loc[len(df)] = accuracy\n",
    "df.loc[len(df)] = frac_clean\n",
    "df.insert(0, 'Metric', ['Sel Samples', 'Precision', 'Recall', 'Specificity', 'Accuracy', 'Fraction'])\n",
    "df['CLK'] = k_mean_stat\n",
    "df['SAME'] = fnaes_stat\n",
    "\n",
    "print(df)\n",
    "print(file_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(file_root+'/metric.txt', index=False, header=True, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
